<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VR眼动追踪实验</title>
    <script src="https://cdn.jsdelivr.net/gh/Steven47444/webgazer-test@main/webgazer.js"></script>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://www.webrtc-experiment.com/RecordRTC.js"></script>
    <style>
        body {
            margin: 0;
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background-color: #f0f0f0;
            position: relative;
        }
        h1 {
            text-align: center;
        }
        .container {
            width: 80%;
            text-align: center;
            background-color: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
            position: relative;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            color: white;
            background-color: #007bff;
            cursor: pointer;
            font-size: 16px;
            position: relative;
            z-index: 10000;
        }
        button:disabled {
            background-color: #ccc;
        }
        #experimentContainer, #calibrationContainer, #finalMessageContainer, #videoInstructions {
            display: none;
        }
        #scene {
            position: fixed;
            top: 0;
            left: 0;
            z-index: 0;
        }
        #finalMessageContainer {
            position: fixed;
            z-index: 9999;
        }
        #recordingStatus {
            position: fixed;
            top: 20px;
            right: 20px;
            background: #ff4444;
            color: white;
            padding: 8px 15px;
            border-radius: 5px;
            display: none;
            z-index: 10000;
        }
        .overlay-hidden {
            display: none !important;
        }
    </style>
</head>
<body>

    <!-- 实验说明页面 -->
    <div class="container" id="instructionContainer">
        <h1>实验说明</h1>
        <p>感谢您参与本次实验！</p>
        <p>本次实验任务是自由观看一段3分钟的VR全景视频，在实验期间，我们将会收集您的眼动数据并录制屏幕。</p>
        <p>在VR全景视频中，您可以通过鼠标左右拖动屏幕来改变主视角。</p>
        <p>视频结束后需要您再扫码填写一份3分钟左右的问卷。</p>
        <button id="consentButton">我已知情并同意参加实验</button>
    </div>

    <!-- 校准说明页面 -->
    <div class="container" id="calibrationContainer">
        <h1>校准说明</h1>
        <p>为了更准确地收集眼动数据，您需要进行眼动校准。</p>
        <p>请点击下面的“开始校准”按钮进行校准，完成后请记下您的准确率并直接返回该网页。</p>
        <p>并点击“我已完成校准，直接开始实验”按钮开始实验。</p>
        <button id="startCalibrationButton">我未完成校准，开始校准</button>
        <br><br>
        <button id="skipCalibrationButton">我已完成校准，直接开始实验</button>
        <img src="instruction.png" alt="Instruction" style="width: 100%; max-width: 500px; margin-top: 20px; margin-bottom: 20px;" />
    </div>

    <!-- 实验页面 -->
    <div class="container" id="experimentContainer">
        <h1>实验开始</h1>
        <p>请点击“开始实验”按钮，然后观看视频。</p>
        <p>点击后会有5秒准备时间。</p>
        <button id="startExperimentButton">开始实验</button>
    </div>

    <!-- 提示视频开始播放 -->
    <div class="container" id="videoInstructions">
        <h1>实验准备中</h1>
        <p>请您点击录制整个屏幕并共享后静坐5秒，实验视频会自动播放。</p>
    </div>

    <!-- 视频播放页面 -->
    <a-scene id="scene" embedded>
        <a-assets>
            <video id="vr-video" 
                   src="bayi-360.mp4" 
                   loop="false" 
                   preload="none"
                   autoplay="false"
                   muted></video>
        </a-assets>
        <a-sky id="sky" src="#vr-video" rotation="0 0 0" visible="false"></a-sky>
    </a-scene>

    <!-- 结束页面 -->
    <div class="container" id="finalMessageContainer">
        <h1>实验结束</h1>
        <p>请将您的眼动数据和屏幕录制视频发给主试。</p>
        <p>并请您扫描以下问卷二维码。</p>
        <p>感谢您的参与！</p>
        <img src="qrcode.png" alt="QR Code" style="width: 200px; height: 200px; margin-top: 20px;" />
    </div>

    <!-- 录制状态提示 -->
    <div id="recordingStatus">● 录制中</div>

    <script>
        let gazeData = [];
        let isCollecting = false;
        let recorder;
        let isRecording = false;
        let videoElement = document.getElementById('vr-video');
        let skyElement = document.getElementById('sky');
        let stream;
        let recordingStartTime;

        // 初始化WebGazer.js
        window.onload = function() {
            webgazer.setRegression('ridge').setTracker('TLD').begin();

            document.getElementById('consentButton').onclick = () => showSection('calibrationContainer');
            document.getElementById('startCalibrationButton').onclick = () => window.location.href = 'https://webgazer.cs.brown.edu/calibration.html?#';
            document.getElementById('skipCalibrationButton').onclick = () => showSection('experimentContainer');
            document.getElementById('startExperimentButton').onclick = startExperiment;
            document.getElementById('finalMessageContainer').style.display = 'none';

            // 监听眼动数据
            webgazer.setGazeListener(function(data, elapsedTime) {
                if (data) {
                    const xprediction = data.x;
                    const yprediction = data.y;
                    const timestamp = elapsedTime;

                    // 保存眼动数据
                    gazeData.push({ x: xprediction, y: yprediction, timestamp: timestamp });

                    // 每秒保存一次数据
                    if (gazeData.length % 30 === 0) {  // 30个数据点约等于1秒
                        console.log("Saving gaze data...");
                    }
                }
            });
        };

        // 开始实验
        function startExperiment() {
            showSection('videoInstructions');
            setTimeout(() => {
                skyElement.setAttribute('visible', true);
                videoElement.play();
                videoElement.muted = false;  // 取消静音
                startRecording();
            }, 5000);
        }

        // 显示不同的实验界面
        function showSection(sectionId) {
            const sections = ['instructionContainer', 'calibrationContainer', 'experimentContainer', 'finalMessageContainer', 'videoInstructions'];
            sections.forEach(id => {
                document.getElementById(id).style.display = id === sectionId ? 'block' : 'none';
            });
        }

        // 保存眼动数据为 .js 文件
        function saveGazeData() {
            const gazeDataBlob = new Blob([`const gazeData = ${JSON.stringify(gazeData)};`], { type: 'application/javascript' });
            const url = URL.createObjectURL(gazeDataBlob);
            const link = document.createElement('a');
            link.href = url;
            link.download = `gazeData_${Date.now()}.js`;
            link.click();
        }

        // 开始录制函数
        function startRecording() {
            navigator.mediaDevices.getDisplayMedia({ video: true, audio: true }).then(function(stream) {  // 使用 getDisplayMedia
                recorder = RecordRTC(stream, {
                    type: 'video'
                });
                recorder.startRecording();
                isRecording = true;
                document.getElementById('recordingStatus').style.display = 'block';
            }).catch(function(error) {
                console.error('Failed to get screen media stream:', error);
            });
        }


        // 停止录制并保存数据函数
        function stopRecordingAndSave() {
            if (isRecording) {
                isRecording = false;
                recorder.stopRecording(function() {
                    // 保存视频文件
                    recorder.save(`experiment_video_${Date.now()}.webm`);
                });
                document.getElementById('recordingStatus').style.display = 'none';
            }
        }

        // 在视频结束时停止录制并保存眼动数据和视频
        videoElement.onended = function() {
            stopRecordingAndSave(); // 停止录制并保存视频
            saveGazeData(); // 保存眼动数据
            webgazer.pause(); // 停止眼动追踪
            showSection('finalMessageContainer'); // 显示实验结束页面
        };

    </script>

</body>
</html>
