<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VR眼动追踪实验</title>
    <script src="https://cdn.jsdelivr.net/gh/Steven47444/webgazer-test@main/webgazer.js"></script>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://www.webrtc-experiment.com/RecordRTC.js"></script>
    <style>
        body {
            margin: 0;
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background-color: #f0f0f0;
            position: relative;
        }
        h1 {
            text-align: center;
        }
        .container {
            width: 80%;
            text-align: center;
            background-color: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
            position: relative;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            color: white;
            background-color: #007bff;
            cursor: pointer;
            font-size: 16px;
            position: relative;
            z-index: 10000;
        }
        button:disabled {
            background-color: #ccc;
        }
        #experimentContainer, #calibrationContainer, #finalMessageContainer, #videoInstructions {
            display: none;
        }
        #scene {
            position: fixed;
            top: 0;
            left: 0;
            z-index: 0;
        }
        #finalMessageContainer {
            position: fixed;
            z-index: 9999;
        }
        .overlay-hidden {
            display: none !important;
        }
    </style>
</head>
<body>

    <!-- 实验说明页面 -->
    <div class="container" id="instructionContainer">
        <h1>实验说明</h1>
        <p>感谢您参与本次实验！</p>
        <p>本次实验任务是自由观看一段3分钟的VR全景视频，在实验期间，我们将会收集您的眼动数据并录制屏幕。</p>
        <p>在VR全景视频中，您可以通过鼠标左右拖动屏幕来改变主视角。</p>
        <p>视频结束后需要您再扫码填写一份3分钟左右的问卷。</p>
        <button id="consentButton">我已知情并同意参加实验</button>
    </div>

    <!-- 校准说明页面 -->
    <div class="container" id="calibrationContainer">
        <h1>校准说明</h1>
        <p>为了更准确地收集眼动数据，您需要进行眼动校准。</p>
        <p>请点击下面的“开始校准”按钮进行校准，完成后请记下您的准确率并直接返回该网页。</p>
        <p>并点击“我已完成校准，直接开始实验”按钮开始实验。</p>
        <button id="startCalibrationButton">我未完成校准，开始校准</button>
        <br><br>
        <button id="skipCalibrationButton">我已完成校准，直接开始实验</button>
        
        <!-- 插入图片 -->
        <img src="instruction.png" alt="Instruction" style="width: 100%; max-width: 500px; margin-top: 20px; margin-bottom: 20px;" />
    </div>

    <!-- 实验页面 -->
    <div class="container" id="experimentContainer">
        <h1>实验开始</h1>
        <p>请点击“开始实验”按钮，然后观看视频。</p>
        <p>点击后会有5秒准备时间，此为正常实验准备时间。</p>
        <p>如果视频播放期间出现问题，点击右下角VR按钮再按Esc退出即可。</p>
        <button id="startExperimentButton">开始实验</button>
    </div>

    <!-- 提示视频开始播放 -->
    <div class="container" id="videoInstructions">
        <h1>实验准备中</h1>
        <p>请您点击录制整个屏幕并共享后静坐5秒，实验视频会自动播放。</p>
    </div>

    <!-- 视频播放页面 -->
    <a-scene id="scene" embedded>
        <a-assets>
            <video id="vr-video" src="bayi-360.mp4" loop="false" preload="auto"></video>
        </a-assets>
        <a-sky id="sky" src="#vr-video" rotation="0 0 0" visible="false"></a-sky>
    </a-scene>

    <!-- 结束页面 -->
    <div class="container" id="finalMessageContainer">
        <h1>实验结束</h1>
        <p>请将您的眼动数据和屏幕录制视频发给主试。</p>
        <p>并请您扫描以下问卷二维码。</p>
        <p>感谢您的参与！</p>
    
        <!-- 插入二维码图片 -->
        <img src="qrcode.png" alt="QR Code" style="width: 200px; height: 200px; margin-top: 20px;" />
    </div>

    <script>
        let gazeData = [];
        let isCollecting = false;
        let recorder;
        let isRecording = false;
        let videoElement = document.getElementById('vr-video');
        let skyElement = document.getElementById('sky');
        let stream;

        videoElement.addEventListener('canplaythrough', function() {
            videoElement.play();
        });

        videoElement.addEventListener('ended', handleVideoEnd);

        window.onload = function() {
            webgazer.setRegression('ridge').setTracker('TLD').begin();

            document.getElementById('consentButton').onclick = () => showSection('calibrationContainer');
            document.getElementById('startCalibrationButton').onclick = () => window.location.href = 'https://webgazer.cs.brown.edu/calibration.html?#';
            document.getElementById('skipCalibrationButton').onclick = () => showSection('experimentContainer');
            document.getElementById('startExperimentButton').onclick = startExperimentFlow;
        };

        function showSection(sectionId) {
            document.querySelectorAll('.container').forEach(el => el.style.display = 'none');
            const section = document.getElementById(sectionId);
            if (section) section.style.display = 'block';
        }

        async function startExperimentFlow() {
            showSection('videoInstructions');
            try {
                await startRecording();
                setTimeout(() => {
                    showSection(null);
                    document.getElementById('scene').classList.remove('overlay-hidden');
                    skyElement.setAttribute('visible', 'true');  
                    videoElement.play();
                    startGazeTracking();
                }, 5000);
            } catch (error) {
                console.error('启动实验失败:', error);
            }
        }

        function startGazeTracking() {
            isCollecting = true;
            webgazer.setGazeListener((data) => {
                if (data && isCollecting) {
                    gazeData.push({
                        x: data.x,
                        y: data.y,
                        timestamp: Date.now()
                    });
                }
            });
        }

        async function handleVideoEnd() {
            isCollecting = false;
            webgazer.pause();
            await stopRecording();
            saveGazeData();
            showSection('finalMessageContainer');
        }

        async function startRecording() {
            try {
                stream = await navigator.mediaDevices.getDisplayMedia({ video: true });
                recorder = new RecordRTC(stream, { type: 'video', mimeType: 'video/webm' });
                recorder.startRecording();
                isRecording = true;
            } catch (error) {
                console.error('屏幕录制失败:', error);
            }
        }

        function stopRecording() {
            return new Promise(resolve => {
                if (recorder && isRecording) {
                    recorder.stopRecording(() => {
                        const blob = recorder.getBlob();
                        downloadFile(blob, "recording.webm");
                        isRecording = false;
                        resolve();
                    });
                } else resolve();
            });
        }

        function saveGazeData() {
            if (gazeData.length === 0) return;
            const blob = new Blob([JSON.stringify(gazeData)], { type: 'application/json' });
            downloadFile(blob, "gaze_data.json");
            gazeData = [];
        }

        function downloadFile(blob, filename) {
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            a.click();
            URL.revokeObjectURL(url);
        }
    </script>
</body>
</html>
