<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VR眼动追踪实验</title>
    <script src="https://cdn.jsdelivr.net/gh/Steven47444/webgazer-test@main/webgazer.js"></script>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://www.webrtc-experiment.com/RecordRTC.js"></script>
    <style>
        body {
            margin: 0;
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background-color: #f0f0f0;
            position: relative;
        }
        h1 {
            text-align: center;
        }
        .container {
            width: 80%;
            text-align: center;
            background-color: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
            position: relative;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            color: white;
            background-color: #007bff;
            cursor: pointer;
            font-size: 16px;
            position: relative;
            z-index: 10000;
        }
        button:disabled {
            background-color: #ccc;
        }
        #experimentContainer, #calibrationContainer, #finalMessageContainer, #videoInstructions {
            display: none;
        }
        #scene {
            position: fixed;
            top: 0;
            left: 0;
            z-index: 0;
        }
        #finalMessageContainer {
            position: fixed;
            z-index: 9999;
        }
        #recordingStatus {
            position: fixed;
            top: 20px;
            right: 20px;
            background: #ff4444;
            color: white;
            padding: 8px 15px;
            border-radius: 5px;
            display: none;
            z-index: 10000;
        }
        .overlay-hidden {
            display: none !important;
        }
    </style>
</head>
<body>

    <!-- 实验说明页面 -->
    <div class="container" id="instructionContainer">
        <h1>实验说明</h1>
        <p>感谢您参与本次实验！</p>
        <p>本次实验任务是自由观看一段3分钟的VR全景视频，在实验期间，我们将会收集您的眼动数据并录制屏幕。</p>
        <p>在VR全景视频中，您可以通过鼠标左右拖动屏幕来改变主视角。</p>
        <p>视频结束后需要您再扫码填写一份3分钟左右的问卷。</p>
        <button id="consentButton">我已知情并同意参加实验</button>
    </div>

    <!-- 校准说明页面 -->
    <div class="container" id="calibrationContainer">
        <h1>校准说明</h1>
        <p>为了更准确地收集眼动数据，您需要进行眼动校准。</p>
        <p>请点击下面的“开始校准”按钮进行校准，完成后请记下您的准确率并直接返回该网页。</p>
        <p>并点击“我已完成校准，直接开始实验”按钮开始实验。</p>
        <button id="startCalibrationButton">我未完成校准，开始校准</button>
        <br><br>
        <button id="skipCalibrationButton">我已完成校准，直接开始实验</button>
        <img src="instruction.png" alt="Instruction" style="width: 100%; max-width: 500px; margin-top: 20px; margin-bottom: 20px;" />
    </div>

    <!-- 实验页面 -->
    <div class="container" id="experimentContainer">
        <h1>实验开始</h1>
        <p>请点击“开始实验”按钮，然后观看视频。</p>
        <p>点击后会有5秒准备时间。</p>
        <button id="startExperimentButton">开始实验</button>
    </div>

    <!-- 提示视频开始播放 -->
    <div class="container" id="videoInstructions">
        <h1>实验准备中</h1>
        <p>请您点击录制整个屏幕并共享后静坐5秒，实验视频会自动播放。</p>
    </div>

    <!-- 视频播放页面 -->
    <a-scene id="scene" embedded>
        <a-assets>
            <video id="vr-video" 
                   src="bayi-360.mp4" 
                   loop="false" 
                   preload="none"
                   autoplay="false"
                   muted></video>
        </a-assets>
        <a-sky id="sky" src="#vr-video" rotation="0 0 0" visible="false"></a-sky>
    </a-scene>

    <!-- 结束页面 -->
    <div class="container" id="finalMessageContainer">
        <h1>实验结束</h1>
        <p>请将您的眼动数据和屏幕录制视频发给主试。</p>
        <p>并请您扫描以下问卷二维码。</p>
        <p>感谢您的参与！</p>
        <img src="qrcode.png" alt="QR Code" style="width: 200px; height: 200px; margin-top: 20px;" />
    </div>

    <!-- 录制状态提示 -->
    <div id="recordingStatus">● 录制中</div>

    <script>
        let gazeData = [];
        let isCollecting = false;
        let recorder;
        let isRecording = false;
        let videoElement = document.getElementById('vr-video');
        let skyElement = document.getElementById('sky');
        let stream;
        let recordingStartTime;

        window.onload = function() {
            webgazer.setRegression('ridge').setTracker('TLD').begin();

            document.getElementById('consentButton').onclick = () => showSection('calibrationContainer');
            document.getElementById('startCalibrationButton').onclick = () => window.location.href = 'https://webgazer.cs.brown.edu/calibration.html?#';
            document.getElementById('skipCalibrationButton').onclick = () => showSection('experimentContainer');
            document.getElementById('startExperimentButton').onclick = startExperimentFlow;
        };

        async function startScreenRecording() {
            try {
                stream = await navigator.mediaDevices.getDisplayMedia({
                    video: { mediaSource: "screen" },
                    audio: false
                });

                recorder = RecordRTC(stream, {
                    type: 'video',
                    mimeType: 'video/webm;codecs=vp9',
                    timeSlice: 1000,
                    ondataavailable: function(blob) {
                        // 实时保存数据块
                    }
                });

                recorder.startRecording();
                isRecording = true;
                recordingStartTime = Date.now();
                document.getElementById('recordingStatus').style.display = 'block';

                videoElement.addEventListener('ended', stopRecordingAndSave);
                
            } catch (error) {
                console.error('屏幕录制失败:', error);
                alert('必须允许屏幕共享才能继续实验！');
                location.reload();
            }
        }

        async function stopRecordingAndSave() {
            if (!isRecording) return;
            
            return new Promise(resolve => {
                recorder.stopRecording(() => {
                    const blob = recorder.getBlob();
                    const filename = `recording_${Date.now()}.webm`;
                    
                    // 创建下载链接
                    const link = document.createElement('a');
                    link.href = URL.createObjectURL(blob);
                    link.download = filename;
                    link.click();

                    // 保存眼动数据为JSON文件
                    const gazeDataBlob = new Blob([JSON.stringify(gazeData)], { type: 'application/json' });
                    const gazeDataLink = document.createElement('a');
                    gazeDataLink.href = URL.createObjectURL(gazeDataBlob);
                    gazeDataLink.download = `gazeData_${Date.now()}.json`;
                    gazeDataLink.click();

                    isRecording = false;
                    stream.getTracks().forEach(track => track.stop());
                    document.getElementById('recordingStatus').style.display = 'none';
                    resolve();
                });
            });
        }

        async function startExperimentFlow() {
            // 先启动屏幕录制
            await startScreenRecording();
            
            showSection('videoInstructions');

            // 初始化播放权限
            try {
                await videoElement.play();
                videoElement.pause();
                videoElement.currentTime = 0;
            } catch (error) {
                console.error('播放准备失败:', error);
            }

            setTimeout(async () => {
                showSection(null);
                document.getElementById('scene').classList.remove('overlay-hidden');
                skyElement.setAttribute('visible', 'true');
                videoElement.play();
            }, 5000);
        }

        function showSection(sectionId) {
            ['instructionContainer', 'calibrationContainer', 'experimentContainer', 'videoInstructions', 'finalMessageContainer'].forEach(id => {
                document.getElementById(id).style.display = id === sectionId ? 'block' : 'none';
            });
        }

        // 记录眼动数据
        webgazer.setGazeListener((data, elapsedTime) => {
            if (data == null || !isCollecting) return;
            gazeData.push({
                timestamp: elapsedTime,
                x: data.x,
                y: data.y
            });
        });
    </script>
</body>
</html>
